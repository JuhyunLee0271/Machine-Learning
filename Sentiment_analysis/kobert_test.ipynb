{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers==3.0.2\n",
    "!pip install torch\n",
    "\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#Dataset, Classifier\n",
    "from prerequisite import BERTDataset, BERTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# LOAD BERT, Vocabulary \n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 20\n",
    "max_grad_norm = 1\n",
    "log_interval = 100\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained KoBERT model\n",
    "PATH = './'\n",
    "model = torch.load(PATH + 'trained_kobert.pt')\n",
    "model.load_state_dict(torch.load(PATH + 'model_state_dict.pt'))\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_softmax(a) : \n",
    "    c = np.max(a) # 최댓값\n",
    "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = (exp_a / sum_exp_a) * 100\n",
    "    return np.round(y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict model \n",
    "def predict(predict_sentence):\n",
    "    \n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            min_v = min(logits)\n",
    "            total = 0\n",
    "            probability = []\n",
    "            logits = np.round(new_softmax(logits), 3).tolist()\n",
    "            for logit in logits:\n",
    "                print(logit)\n",
    "                probability.append(np.round(logit, 3))\n",
    "\n",
    "            if np.argmax(logits) == 0:  emotion = \"기쁨\"\n",
    "            elif np.argmax(logits) == 1: emotion = \"불안\"\n",
    "            elif np.argmax(logits) == 2: emotion = '당황'\n",
    "            elif np.argmax(logits) == 3: emotion = '슬픔'\n",
    "            elif np.argmax(logits) == 4: emotion = '분노'\n",
    "            elif np.argmax(logits) == 5: emotion = '상처'\n",
    "\n",
    "            probability.append(emotion)\n",
    "            print(probability)\n",
    "    return probability"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28a4a7593db0aeb32591c6d880fc2645b662bf2e894ccdeb1773515f315db3ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('MLvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

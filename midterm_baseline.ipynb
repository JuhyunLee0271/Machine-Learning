{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YoIYO-hUoKKY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (1.11.0)\n",
            "Requirement already satisfied: torchvision in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from torchvision) (9.1.0)\n",
            "Requirement already satisfied: numpy in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from requests->torchvision) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qZwRe8dCoRet"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'urllib3'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/juhyunlee/Desktop/Github/Machine-Learning/midterm_baseline.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juhyunlee/Desktop/Github/Machine-Learning/midterm_baseline.ipynb#ch0000001?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juhyunlee/Desktop/Github/Machine-Learning/midterm_baseline.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juhyunlee/Desktop/Github/Machine-Learning/midterm_baseline.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, transforms\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juhyunlee/Desktop/Github/Machine-Learning/midterm_baseline.ipynb#ch0000001?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Variable\n",
            "File \u001b[0;32m~/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m io\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/__init__.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
            "File \u001b[0;32m~/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_optical_flow\u001b[39;00m \u001b[39mimport\u001b[39;00m KittiFlow, Sintel, FlyingChairs, FlyingThings3D, HD1K\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcaltech\u001b[39;00m \u001b[39mimport\u001b[39;00m Caltech101, Caltech256\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mceleba\u001b[39;00m \u001b[39mimport\u001b[39;00m CelebA\n",
            "File \u001b[0;32m~/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _read_png_16\n\u001b[0;32m---> <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m verify_str_arg\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionDataset\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=16'>17</a>\u001b[0m __all__ \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=17'>18</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mKittiFlow\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSintel\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=21'>22</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHD1K\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/_optical_flow.py?line=22'>23</a>\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, List, Iterable, Optional, TypeVar, Dict, IO, Tuple, Iterator\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[0;32m---> <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py?line=17'>18</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/torchvision/datasets/utils.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_zoo\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
            "File \u001b[0;32m~/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m#   __\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=3'>4</a>\u001b[0m \u001b[39m#  /__)  _  _     _   _ _/   _\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=4'>5</a>\u001b[0m \u001b[39m# / (   (- (/ (/ (- _)  /  _)\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=5'>6</a>\u001b[0m \u001b[39m#          /\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=8'>9</a>\u001b[0m \u001b[39mRequests HTTP Library\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=9'>10</a>\u001b[0m \u001b[39m~~~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=39'>40</a>\u001b[0m \u001b[39m:license: Apache 2.0, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=40'>41</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=42'>43</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib3\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=43'>44</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/juhyunlee/miniconda3/envs/MLvenv/lib/python3.8/site-packages/requests/__init__.py?line=44'>45</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m RequestsDependencyWarning\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urllib3'"
          ]
        }
      ],
      "source": [
        "#Import Libraries\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOG5f5jlo-XT"
      },
      "outputs": [],
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1000\n",
        "args['test_batch_size']=1000\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=5000 // args['batch_size']\n",
        "args['cuda']=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGdPKyBuo-gJ"
      },
      "outputs": [],
      "source": [
        "#load the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jArDr-s3pBOJ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use sigmoid for activation function\n",
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.sigmoid(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.sigmoid(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use tanh for activation function \n",
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.tanh(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.tanh(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leaky ReLU\n",
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def LeakyReLU(self, x):\n",
        "        return x.clamp(min=0) + x.clamp(max=0)*0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cAisI4rXpBUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data))\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRTIDcni1IDu"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "midterm_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

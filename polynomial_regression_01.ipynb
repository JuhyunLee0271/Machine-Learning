{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"polynomial_regression_01.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyN5SzJFqkOCUwDH/ouVzZNL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["다중 회귀(Multiple Regression)\n","- 여러 개의 특성을 사용한 선형 회귀\n","\n","특성 공학(feature engineering)\n","- 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업 \n","\n","변환기\n","- 특성을 만들거나 전처리하기 위한 클래스\n","- PolynomialFeatures (각 특성의 제곱, 두 특성의 곱 특성 추가)\n","\n","샘플 개수보다 특성이 많다면 -> 과대적합이 될 가능성\n","- 훈련 세트에 대해서는 완벽하게 학습할 수 있지만, 훈련 세트에 너무 과대적합되므로 테스트 세트에서는 형편없는 점수를 나타낼 수 있음\n","\n","규제 \n","- 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것\n","- 즉, 모델이 훈련 세트에 과대적합되지 않도록 만드는 것 ( 특성에 곱해지는 계수(기울기)의 크기를 작게 만드는 것 )\n","\n","릿지 회귀\n","- 계수를 제곱한 값을 기준으로 규제를 적용\n","\n","라쏘 회귀\n","- 계수의 절댓값을 기준으로 규제를 적용 "],"metadata":{"id":"S6azXorA_xO8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDPf5yzu_GZc"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.linear_model import LinearRegression, Ridge"]},{"cell_type":"code","source":["df = pd.read_csv('https://bit.ly/perch_csv_data')\n","perch_full = df.to_numpy()"],"metadata":{"id":"m6tIWnW3AuIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n","       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n","       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n","       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n","       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n","       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n","       1000.0])"],"metadata":{"id":"ns-bE47_Baog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_input, test_input, train_target, test_target = train_test_split(\n","    perch_full, perch_weight, random_state = 42\n",")"],"metadata":{"id":"sTQ_w1fNBcKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["poly = PolynomialFeatures(include_bias=False)\n","# poly = PolynomialFeatures(include_bias=False, degree=5)\n","poly.fit(train_input)\n","\n","train_poly = poly.transform(train_input)\n","test_poly = poly.transform(test_input)"],"metadata":{"id":"POyUJYVqBx5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = LinearRegression()\n","lr.fit(train_poly, train_target)\n","lr.score(train_poly, train_target)\n","lr.score(test_poly, test_target)"],"metadata":{"id":"PkXvII1fR6xF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 표준 점수 변환: StandardScaler\n","ss = StandardScaler()\n","ss.fit(train_poly)\n","\n","train_scaled = ss.transform(train_poly)\n","test_scaled = ss.transform(test_poly)"],"metadata":{"id":"revFUw-xVGk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ridge = Ridge(alpha=0.1)\n","ridge.fit(train_scaled, train_target)\n","\n","print(ridge.score(train_scaled, train_target))\n","print(ridge.score(test_scaled, test_target))"],"metadata":{"id":"lOtfvvCVXwtX"},"execution_count":null,"outputs":[]}]}